{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826bc2de-1a75-4b07-8ff1-6173f8a985c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim import corpora, models\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Read the text file\n",
    "with open('file.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Tokenize sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    # Initialize stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Tokenize and clean each sentence\n",
    "    cleaned_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # Remove punctuation and numbers\n",
    "        sentence = re.sub(r'[^a-zA-Z\\s]', '', sentence)\n",
    "\n",
    "        # Tokenize words\n",
    "        words = word_tokenize(sentence.lower())\n",
    "\n",
    "        # Remove stopwords\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "\n",
    "        cleaned_sentences.append(words)\n",
    "\n",
    "    return cleaned_sentences, sentences\n",
    "\n",
    "cleaned_sentences, sentences = preprocess_text(text)\n",
    "\n",
    "# Create a dictionary and corpus for LDA\n",
    "dictionary = corpora.Dictionary(cleaned_sentences)\n",
    "corpus = [dictionary.doc2bow(sentence) for sentence in cleaned_sentences]\n",
    "\n",
    "# Apply LDA to find major topics\n",
    "num_topics = 5\n",
    "lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)\n",
    "\n",
    "# Get the topics with their keywords\n",
    "topics = lda_model.show_topics(num_topics=num_topics, num_words=10, formatted=False)\n",
    "\n",
    "# Generate human-readable topic names based on top keywords\n",
    "def generate_topic_name(keywords):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_keywords = [word for word, _ in keywords if word not in stop_words]\n",
    "    if len(filtered_keywords) >= 3:\n",
    "        return f\"{filtered_keywords[0].capitalize()} and {filtered_keywords[1]}: {filtered_keywords[2]}\"\n",
    "    else:\n",
    "        return \" \".join([word.capitalize() for word in filtered_keywords])\n",
    "\n",
    "topic_names = {i: generate_topic_name(keywords) for i, keywords in topics}\n",
    "\n",
    "# Print the topics with their generated names\n",
    "for topic_id, keywords in topics:\n",
    "    print(f\"Topic {topic_id} Heading: {topic_names[topic_id]}\")\n",
    "    print(f\"Keywords: {[word for word, _ in keywords]}\")\n",
    "\n",
    "# Map sentences to topics\n",
    "def map_sentences_to_topics(lda_model, corpus, sentences):\n",
    "    sentence_topics = {}\n",
    "    for i, sentence_bow in enumerate(corpus):\n",
    "        topic_distribution = lda_model.get_document_topics(sentence_bow)\n",
    "        dominant_topic = max(topic_distribution, key=lambda x: x[1])[0]\n",
    "        if dominant_topic not in sentence_topics:\n",
    "            sentence_topics[dominant_topic] = []\n",
    "        sentence_topics[dominant_topic].append(sentences[i])\n",
    "    return sentence_topics\n",
    "\n",
    "sentence_topics = map_sentences_to_topics(lda_model, corpus, sentences)\n",
    "\n",
    "# Print the sentences grouped by topics\n",
    "for topic, sents in sentence_topics.items():\n",
    "    print(f\"Heading: {topic_names[topic]}\")\n",
    "    for sent in sents:\n",
    "        print(f\" - {sent}\")\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
